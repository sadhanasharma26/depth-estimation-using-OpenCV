# -*- coding: utf-8 -*-
"""stereo_vision_group5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JCvwcrRmUej0Kmj_h6cd7eLro189Br9A
"""



import cv2
import numpy as np
import cvzone
from cvzone.SelfiSegmentationModule import SelfiSegmentation

width = 640
height = 640

# Define the cameras to use (camera_1, camera_2)
camera_1 = cv2.VideoCapture (2, cv2.CAP_DSHOW)
camera_1.set(cv2.CAP_PROP_FRAME_WIDTH, width)
camera_1.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
camera_1.set(cv2.CAP_PROP_FPS, 15)
camera_2 = cv2.VideoCapture(1, cv2.CAP_DSHOW)
camera_2.set(cv2.CAP_PROP_FRAME_WIDTH, width)
camera_2.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
camera_1.set(cv2.CAP_PROP_FPS, 15)
# img_left = cv2. imread('11.jpg')
# img_right = cv2.imread('r1.jpg')
segmentor = SelfiSegmentation(0)
# Create a stereo block matching object
# stereo = cv2.StereoM_create(numDisparities=16, blockSize=11)
# Stereo SGBM parameters
window_size = 3
min_disp = 0
num_disp = 64  # Number of disparity levels (adjust as needed)

stereo = cv2.StereoSGBM_create(
    minDisparity=min_disp,
    numDisparities=num_disp,
    blockSize=window_size,
    P1=8 * 3 * window_size ** 2,
    P2=32 * 3 * window_size ** 2,
    disp12MaxDiff=1,
    uniquenessRatio=15,
    speckleWindowSize=200,
    speckleRange=2,
    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY,
)

while True:
    camera_1.grab()
    camera_2.grab()

    # Read the frames from each camera
    ret1, frame1 = camera_1.read()
    ret2, frame2 = camera_2.read()

    frame1 = segmentor.removeBG(frame1, (0,0,0))
    frame2 = segmentor.removeBG(frame2, (0,0,0))

    # Convert the frames to grayscale
    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
    kernel = np.ones((3,3), np.float32)/9
    gray1 = cv2.filter2D(gray1, -1, kernel)
    gray2 = cv2.filter2D(gray2, -1, kernel)
    # Compute the depth map using the stereo block matching object
    depth = stereo.compute (gray1, gray2)

    disparity = (depth - min_disp) / num_disp

    # Normalize the depth map to be between 0 and 255
    norm_depth = cv2.normalize(depth, None, 10, 245, cv2.NORM_MINMAX)

    # Convert the depth map to a color map
    color_depth = cv2.applyColorMap(norm_depth.astype(np.uint8), cv2.COLORMAP_HSV)

    color_depth = cv2.flip(color_depth, 1)
    color_depth = color_depth[:height, :width-100]

    # Display the disparity map using cv2.imshow
    cv2.imshow('Disparity Map', disparity)

    # Display the depth map using cv2.imshow
    cv2.imshow('Depth Map', color_depth)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

camera_1.release()
camera_2.release()

cv2.destroyAllWindows()

# Print disparity and depth values
average_disparity = np.mean(disparity)
average_depth = np.mean(color_depth)
print(f'Average Disparity: {average_disparity}')
print(f'Average Depth (in meters): {average_depth}')

